{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy\n",
    "#pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据源：http://www.sogou.com/labs/resource/ca.php ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>theme</th>\n",
       "      <th>URL</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>汽车</td>\n",
       "      <td>新辉腾　４．２　Ｖ８　４座加长Ｉｎｄｉｖｉｄｕａｌ版２０１１款　最新报价</td>\n",
       "      <td>http://auto.data.people.com.cn/model_15782/</td>\n",
       "      <td>经销商　电话　试驾／订车Ｕ憬杭州滨江区江陵路１７８０号４００８－１１２２３３转５８６４＃保常...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>汽车</td>\n",
       "      <td>９１８　Ｓｐｙｄｅｒ概念车</td>\n",
       "      <td>http://auto.data.people.com.cn/prdview_165423....</td>\n",
       "      <td>呼叫热线　４００８－１００－３００　服务邮箱　ｋｆ＠ｐｅｏｐｌｅｄａｉｌｙ．ｃｏｍ．ｃｎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>汽车</td>\n",
       "      <td>日内瓦亮相　ＭＩＮＩ性能版／概念车－１．６Ｔ引擎</td>\n",
       "      <td>http://auto.data.people.com.cn/news/story_5249...</td>\n",
       "      <td>ＭＩＮＩ品牌在二月曾经公布了最新的ＭＩＮＩ新概念车Ｃｌｕｂｖａｎ效果图，不过现在在日内瓦车展...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>汽车</td>\n",
       "      <td>清仓大甩卖一汽夏利Ｎ５威志Ｖ２低至３．３９万</td>\n",
       "      <td>http://auto.data.people.com.cn/news/story_6144...</td>\n",
       "      <td>清仓大甩卖！一汽夏利Ｎ５、威志Ｖ２低至３．３９万＝日，启新中国一汽强势推出一汽夏利Ｎ５、威志...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>汽车</td>\n",
       "      <td>大众敞篷家族新成员　高尔夫敞篷版实拍</td>\n",
       "      <td>http://auto.data.people.com.cn/news/story_5686...</td>\n",
       "      <td>在今年３月的日内瓦车展上，我们见到了高尔夫家族的新成员，高尔夫敞篷版，这款全新敞篷车受到了众...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                 theme  \\\n",
       "0       汽车  新辉腾　４．２　Ｖ８　４座加长Ｉｎｄｉｖｉｄｕａｌ版２０１１款　最新报价   \n",
       "1       汽车                         ９１８　Ｓｐｙｄｅｒ概念车   \n",
       "2       汽车              日内瓦亮相　ＭＩＮＩ性能版／概念车－１．６Ｔ引擎   \n",
       "3       汽车                清仓大甩卖一汽夏利Ｎ５威志Ｖ２低至３．３９万   \n",
       "4       汽车                    大众敞篷家族新成员　高尔夫敞篷版实拍   \n",
       "\n",
       "                                                 URL  \\\n",
       "0        http://auto.data.people.com.cn/model_15782/   \n",
       "1  http://auto.data.people.com.cn/prdview_165423....   \n",
       "2  http://auto.data.people.com.cn/news/story_5249...   \n",
       "3  http://auto.data.people.com.cn/news/story_6144...   \n",
       "4  http://auto.data.people.com.cn/news/story_5686...   \n",
       "\n",
       "                                             content  \n",
       "0  经销商　电话　试驾／订车Ｕ憬杭州滨江区江陵路１７８０号４００８－１１２２３３转５８６４＃保常...  \n",
       "1       呼叫热线　４００８－１００－３００　服务邮箱　ｋｆ＠ｐｅｏｐｌｅｄａｉｌｙ．ｃｏｍ．ｃｎ  \n",
       "2  ＭＩＮＩ品牌在二月曾经公布了最新的ＭＩＮＩ新概念车Ｃｌｕｂｖａｎ效果图，不过现在在日内瓦车展...  \n",
       "3  清仓大甩卖！一汽夏利Ｎ５、威志Ｖ２低至３．３９万＝日，启新中国一汽强势推出一汽夏利Ｎ５、威志...  \n",
       "4  在今年３月的日内瓦车展上，我们见到了高尔夫家族的新成员，高尔夫敞篷版，这款全新敞篷车受到了众...  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_table('./data/val.txt',names=['category','theme','URL','content'], encoding='utf-8')#按字段来命名\n",
    "df_news = df_news.dropna()#去掉缺失值\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  分词：使用结吧分词器 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿里巴巴集团昨日宣布，将在集团管理层面设立首席数据官岗位（Ｃｈｉｅｆ　Ｄａｔａ　Ｏｆｆｉｃｅｒ），阿里巴巴Ｂ２Ｂ公司ＣＥＯ陆兆禧将会出任上述职务，向集团ＣＥＯ马云直接汇报。＞菹ぃ和６月初的首席风险官职务任命相同，首席数据官亦为阿里巴巴集团在完成与雅虎股权谈判，推进“ｏｎｅ　ｃｏｍｐａｎｙ”目标后，在集团决策层面新增的管理岗位。０⒗锛团昨日表示，“变成一家真正意义上的数据公司”已是战略共识。记者刘夏\n"
     ]
    }
   ],
   "source": [
    "content = df_news.content.values.tolist()#拿出content列的值，转换为list格式(二维)，因为结巴分词器需要list格式\n",
    "print (content[1000])#打印第1000条看一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_S = []#指定一个list存储分完词的结果\n",
    "for line in content:#进行list的遍历\n",
    "    current_segment = jieba.lcut(line)#对新闻主体进行分词\n",
    "    if len(current_segment) > 1 and current_segment != '\\r\\n': #切的刀数大于1且不包含换行符\n",
    "        content_S.append(current_segment)#加到content_S中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_S[1000][:10]#打印第1000条看一下分词结果,显示前10个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TF-IDF ：用结巴的库进行关键词提取###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿里巴巴集团昨日宣布，将在集团管理层面设立首席数据官岗位（Ｃｈｉｅｆ　Ｄａｔａ　Ｏｆｆｉｃｅｒ），阿里巴巴Ｂ２Ｂ公司ＣＥＯ陆兆禧将会出任上述职务，向集团ＣＥＯ马云直接汇报。＞菹ぃ和６月初的首席风险官职务任命相同，首席数据官亦为阿里巴巴集团在完成与雅虎股权谈判，推进“ｏｎｅ　ｃｏｍｐａｎｙ”目标后，在集团决策层面新增的管理岗位。０⒗锛团昨日表示，“变成一家真正意义上的数据公司”已是战略共识。记者刘夏\n",
      "阿里巴巴  集团  首席  岗位  数据\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "index = 1000#看第1000条\n",
    "print (df_news['content'][index])\n",
    "content_S_str = \"\".join(content_S[index])  \n",
    "#extract_tags提取关键词,topK=5代表选择5个关键词\n",
    "print (\"  \".join(jieba.analyse.extract_tags(content_S_str, topK=5, withWeight=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[经销商, 　, 电话, 　, 试驾, ／, 订车, Ｕ, 憬, 杭州, 滨江区, 江陵, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[呼叫, 热线, 　, ４, ０, ０, ８, －, １, ０, ０, －, ３, ０, ０...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Ｍ, Ｉ, Ｎ, Ｉ, 品牌, 在, 二月, 曾经, 公布, 了, 最新, 的, Ｍ, Ｉ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[清仓, 大, 甩卖, ！, 一汽, 夏利, Ｎ, ５, 、, 威志, Ｖ, ２, 低至, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[在, 今年, ３, 月, 的, 日内瓦, 车展, 上, ，, 我们, 见到, 了, 高尔夫...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           content_S\n",
       "0  [经销商, 　, 电话, 　, 试驾, ／, 订车, Ｕ, 憬, 杭州, 滨江区, 江陵, ...\n",
       "1  [呼叫, 热线, 　, ４, ０, ０, ８, －, １, ０, ０, －, ３, ０, ０...\n",
       "2  [Ｍ, Ｉ, Ｎ, Ｉ, 品牌, 在, 二月, 曾经, 公布, 了, 最新, 的, Ｍ, Ｉ...\n",
       "3  [清仓, 大, 甩卖, ！, 一汽, 夏利, Ｎ, ５, 、, 威志, Ｖ, ２, 低至, ...\n",
       "4  [在, 今年, ３, 月, 的, 日内瓦, 车展, 上, ，, 我们, 见到, 了, 高尔夫..."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content=pd.DataFrame({'content_S':content_S})#将分完的词组成DataFrame格式\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去掉停用词，stopwords.txt为停用词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stopword\n",
       "0        !\n",
       "1        \"\n",
       "2        #\n",
       "3        $\n",
       "4        %"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=pd.read_csv(\"stopwords.txt\",index_col=False,sep=\"\\t\",quoting=3,names=['stopword'], encoding='utf-8')\n",
    "stopwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉停用词的函数\n",
    "def drop_stopwords(contents,stopwords):\n",
    "    contents_clean = []\n",
    "    all_words = []\n",
    "    for line in contents:#遍历，分完的词出现在停用词表则去掉\n",
    "        line_clean = []\n",
    "        for word in line:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            line_clean.append(word)#过滤后的词\n",
    "            all_words.append(str(word))#统计所有的词\n",
    "        contents_clean.append(line_clean)\n",
    "    return contents_clean,all_words\n",
    "    #print (contents_clean)\n",
    "        \n",
    "# 转为list格式\n",
    "contents = df_content.content_S.values.tolist()    \n",
    "stopwords = stopwords.stopword.values.tolist()\n",
    "# 去掉停用词\n",
    "contents_clean,all_words = drop_stopwords(contents,stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LDA建模 ：主题模型###\n",
    "\n",
    "格式要求：list of list形式，分词好的的整个语料，list of list外面为文章，里面为分号的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities#gensim库用来作自然语言处理\n",
    "import gensim\n",
    "#http://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#做映射，相当于词袋\n",
    "dictionary = corpora.Dictionary(contents_clean)#做成字典\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in contents_clean]#在每个句子中都做自然模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立LDA模型，传入语料、映射字典、指定要得到多少个主题(无监督)\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=20) #类似Kmeans自己指定K值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005*\"皮肤\" + 0.005*\"李小璐\" + 0.005*\"肌肤\" + 0.004*\"中\" + 0.004*\"吃\"\n"
     ]
    }
   ],
   "source": [
    "#一号分类结果\n",
    "print (lda.print_topic(1, topn=5))#1代表第1类主题，topn=5为最具代表性的前5个关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004*\"万\" + 0.003*\"号\" + 0.002*\"羲\" + 0.002*\"转\" + 0.002*\"元\"\n",
      "0.021*\"男人\" + 0.012*\"女人\" + 0.012*\"饰演\" + 0.007*\"中\" + 0.004*\"电影\"\n",
      "0.011*\"万\" + 0.010*\"号\" + 0.006*\"观众\" + 0.005*\"导演\" + 0.004*\"演出\"\n",
      "0.016*\"ａ\" + 0.013*\"ｉ\" + 0.008*\"ｎ\" + 0.008*\"ｅ\" + 0.007*\"ｏ\"\n",
      "0.008*\"中\" + 0.005*\"导演\" + 0.004*\"表演\" + 0.004*\"男人\" + 0.004*\"说\"\n",
      "0.004*\"中\" + 0.004*\"短发\" + 0.003*\"万元\" + 0.003*\"Ｖ\" + 0.003*\"Ｔ\"\n",
      "0.006*\"主演\" + 0.006*\"中\" + 0.005*\"剧中\" + 0.005*\"剧组\" + 0.005*\"卫视\"\n",
      "0.006*\"肌肤\" + 0.004*\"中\" + 0.004*\"食物\" + 0.003*\"维生素\" + 0.003*\"教育\"\n",
      "0.005*\"赛季\" + 0.004*\"比赛\" + 0.003*\"联赛\" + 0.002*\"今晚\" + 0.002*\"市场\"\n",
      "0.007*\"中国\" + 0.007*\"中\" + 0.004*\"比赛\" + 0.003*\"产品\" + 0.003*\"生产\"\n"
     ]
    }
   ],
   "source": [
    "for topic in lda.print_topics(num_topics=10, num_words=5):#分别打印10个主题各个最具代表性的5个关键词\n",
    "    print (topic[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用贝叶斯分类器做分类###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>[天气, 炎热, 补水, 变得, 美国, 跑步, 世界, 杂志, 报道, 喝水, 身体, 补...</td>\n",
       "      <td>时尚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>[不想, 说, 话, 刺激, 说, 做, 只能, 走, 离开, 伤心地, 想起, 一句, 话...</td>\n",
       "      <td>时尚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>[岁, 刘晓庆, 最新, 嫩照, Ｏ, 衷, 诘, 牧跸, 庆, 看不出, 岁, 秒杀, 刘...</td>\n",
       "      <td>时尚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>[导语, 做, 爸爸, 一种, 幸福, 无论是, 领养, 亲生, 更何况, 影视剧, 中, ...</td>\n",
       "      <td>时尚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[全球, 最美, 女人, 合成图, 国, 整形外科, 教授, 李承哲, 国际, 学术, 杂志...</td>\n",
       "      <td>时尚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         contents_clean label\n",
       "4995  [天气, 炎热, 补水, 变得, 美国, 跑步, 世界, 杂志, 报道, 喝水, 身体, 补...    时尚\n",
       "4996  [不想, 说, 话, 刺激, 说, 做, 只能, 走, 离开, 伤心地, 想起, 一句, 话...    时尚\n",
       "4997  [岁, 刘晓庆, 最新, 嫩照, Ｏ, 衷, 诘, 牧跸, 庆, 看不出, 岁, 秒杀, 刘...    时尚\n",
       "4998  [导语, 做, 爸爸, 一种, 幸福, 无论是, 领养, 亲生, 更何况, 影视剧, 中, ...    时尚\n",
       "4999  [全球, 最美, 女人, 合成图, 国, 整形外科, 教授, 李承哲, 国际, 学术, 杂志...    时尚"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.DataFrame({'contents_clean':contents_clean,'label':df_news['category']})\n",
    "# 显示后5行\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['汽车', '财经', '科技', '健康', '体育', '教育', '文化', '军事', '娱乐', '时尚'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.unique()#看有多少个不重复的值，即分了多少类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[经销商, 电话, 试驾, 订车, Ｕ, 憬, 杭州, 滨江区, 江陵, 路, 号, 转, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[呼叫, 热线, 服务, 邮箱, ｋ, ｆ, ｐ, ｅ, ｏ, ｐ, ｌ, ｅ, ｄ, ａ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Ｍ, Ｉ, Ｎ, Ｉ, 品牌, 二月, 公布, 最新, Ｍ, Ｉ, Ｎ, Ｉ, 新, 概念...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[清仓, 甩卖, 一汽, 夏利, Ｎ, 威志, Ｖ, 低至, 万, 启新, 中国, 一汽, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[日内瓦, 车展, 见到, 高尔夫, 家族, 新, 成员, 高尔夫, 敞篷版, 款, 全新,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      contents_clean  label\n",
       "0  [经销商, 电话, 试驾, 订车, Ｕ, 憬, 杭州, 滨江区, 江陵, 路, 号, 转, ...      1\n",
       "1  [呼叫, 热线, 服务, 邮箱, ｋ, ｆ, ｐ, ｅ, ｏ, ｐ, ｌ, ｅ, ｄ, ａ,...      1\n",
       "2  [Ｍ, Ｉ, Ｎ, Ｉ, 品牌, 二月, 公布, 最新, Ｍ, Ｉ, Ｎ, Ｉ, 新, 概念...      1\n",
       "3  [清仓, 甩卖, 一汽, 夏利, Ｎ, 威志, Ｖ, 低至, 万, 启新, 中国, 一汽, ...      1\n",
       "4  [日内瓦, 车展, 见到, 高尔夫, 家族, 新, 成员, 高尔夫, 敞篷版, 款, 全新,...      1"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {\"汽车\": 1, \"财经\": 2, \"科技\": 3, \"健康\": 4, \"体育\":5, \"教育\": 6,\"文化\": 7,\"军事\": 8,\"娱乐\": 9,\"时尚\": 0}#写成键值对\n",
    "df_train['label'] = df_train['label'].map(label_mapping)#用map将label映射为0-9\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#将数据分为训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_train['contents_clean'].values, df_train['label'].values, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'中新网 上海 日电 于俊 父亲节 网络 吃 一顿 电影 快餐 微 电影 爸 对不起 我爱你 定于 本月 父亲节 当天 各大 视频 网站 首映 葜 谱 鞣 剑 保慈 障蚣 钦 呓 樯 埽 ⒌ 缬 埃 ǎ 停 椋 悖 颍 铩 妫 椋 恚 称 微型 电影 新 媒体 平台 播放 状态 短时 休闲 状态 观看 完整 策划 系统 制作 体系 支持 显示 较完整 故事情节 电影 微 超短 放映 微 周期 制作 天 数周 微 规模 投资 人民币 几千 数万元 每部 内容 融合 幽默 搞怪 时尚 潮流 人文 言情 公益 教育 商业 定制 主题 单独 成篇 系列 成剧 唇 开播 微 电影 爸 对不起 我爱你 讲述 一对 父子 观念 缺少 沟通 导致 关系 父亲 传统 固执 钟情 传统 生活 方式 儿子 新派 音乐 达 习惯 晚出 早 生活 性格 张扬 叛逆 两种 截然不同 生活 方式 理念 差异 一场 父子 间 拉开序幕 子 失手 打破 父亲 心爱 物品 父亲 赶出 家门 剧情 演绎 父亲节 妹妹 哥哥 化解 父亲 这场 矛盾 映逋坏 嚼 斫 狻 ⒍ 粤 ⒌ 桨容 争执 退让 传统 尴尬 父子 尴尬 情 男人 表达 心中 那份 感恩 一杯 滤挂 咖啡 父亲节 变得 温馨 镁 缬 缮 虾 Ｎ 逄 煳 幕 传播 迪欧 咖啡 联合 出品 出品人 希望 观摩 扪心自问 父亲节 父亲 记得 父亲 生日 哪一天 父亲 爱喝 跨出 家门 那一刻 感觉 一颗 颤动 心 操劳 天下 儿女 父亲节 大声 喊出 父亲 家人 爱 完'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer向量构造器的输入要求为list串，每个文章用逗号分开，用空格来进行分词\n",
    "#构造输入的形式\n",
    "words = []\n",
    "for line_index in range(len(x_train)):\n",
    "    try:\n",
    "        #x_train[line_index][word_index] = str(x_train[line_index][word_index])\n",
    "        words.append(' '.join(x_train[line_index]))#将list of list格式转化为list串，用空格分开\n",
    "    except:\n",
    "        print (line_index,word_index)\n",
    "words[0]#打印训练的第一个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750\n"
     ]
    }
   ],
   "source": [
    "print (len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'cat', 'dog', 'fish']\n",
      "[[0 1 1 1]\n",
      " [0 2 1 0]\n",
      " [1 0 0 1]\n",
      " [1 0 0 0]]\n",
      "[2 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "#此部分用来举例，看输入的格式\n",
    "from sklearn.feature_extraction.text import CountVectorizer#CountVectorizer为向量构造器，把词或句子转化为向量\n",
    "texts=[\"dog cat fish\",\"dog cat cat\",\"fish bird\", 'bird']\n",
    "cv = CountVectorizer()#实例化出一个对象\n",
    "cv_fit=cv.fit_transform(texts)#按指定标准做转化\n",
    "\n",
    "print(cv.get_feature_names())#打印不重复的单词\n",
    "print(cv_fit.toarray())#按上面的text挨个进行显示\n",
    "#由此可知此构造器的输入要求为list，每个文章用逗号分开，用空格来进行分词\n",
    "\n",
    "print(cv_fit.toarray().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=False, max_df=1.0, max_features=4000, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer#CountVectorizer为向量构造器，把词或句子转化为向量\n",
    "#设置向量转换规则\n",
    "vec = CountVectorizer(analyzer='word', max_features=4000,  lowercase = False)#analyzer='word'根据词来构造向量\n",
    "# 将词转化为向量\n",
    "vec.fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB#拿出贝叶斯分类器\n",
    "classifier = MultinomialNB()\n",
    "# 进行模型的训练\n",
    "classifier.fit(vec.transform(words), y_train)#transform(words)转换为向量，y_train为label值，即输入特征和label值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#对测试集也进行输入格式的处理\n",
    "test_words = []\n",
    "for line_index in range(len(x_test)):\n",
    "    try:\n",
    "        #x_train[line_index][word_index] = str(x_train[line_index][word_index])\n",
    "        test_words.append(' '.join(x_test[line_index]))\n",
    "    except:\n",
    "         print (line_index,word_index)\n",
    "test_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.804"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(test_words), y_test)#计算精度"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
